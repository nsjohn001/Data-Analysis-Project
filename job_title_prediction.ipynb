{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOJr20lWbWxp"
      },
      "source": [
        "\n",
        "# Global Fashion Retail Analytics Dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEzVeLDTbeD0"
      },
      "source": [
        "**Upload file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0wQeqZ7f9hU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc95b5d7-0e37-49ca-97c1-8ae5528c3823"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7-cbkKKYoSw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"/content/drive/My Drive/Colab Notebooks/customers.csv\"\n",
        "df = pd.read_csv(file_path, encoding=\"latin1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu1BXU1HzT06"
      },
      "source": [
        "**Data Inspection: Begin by loading and exploring the dataset (e.g., checking for missing values, data types, and basic statistics).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0H9xHQ4izer"
      },
      "source": [
        "**Access the File in Colab**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuyXSwkBiYWl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"/content/drive/My Drive/Colab Notebooks/customers.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.head())  # Display first few rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4SXkHqnih5v"
      },
      "source": [
        "**Check for Missing Values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTu3QdL7iwgz"
      },
      "outputs": [],
      "source": [
        "print(df.isnull().sum())  # Shows the number of missing values per column\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5MAjOfzi00-"
      },
      "outputs": [],
      "source": [
        "print(df.isnull().sum().sum())  # Total missing values in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abynLdJNlP0D"
      },
      "outputs": [],
      "source": [
        "#visualize missing values using seaborn\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(df.isnull(), cmap=\"viridis\", cbar=False, yticklabels=False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acYd9IfIlkDm"
      },
      "source": [
        "**Check Data Types**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8940kzWfl3_9"
      },
      "outputs": [],
      "source": [
        "print(df.dtypes) # Shows the data types per column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrO4vHDtn3cU"
      },
      "source": [
        "**Basic Statistics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBj4ciQVoBm1"
      },
      "outputs": [],
      "source": [
        "print(df.describe())  # Shows statistics for numerical columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoWmLzHrqfmy"
      },
      "outputs": [],
      "source": [
        "print(df.describe(include=['O']))  # Shows statistics for categorical columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iAFp1Yer4V0"
      },
      "source": [
        "**Check Unique Values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usK4JzYur6ks"
      },
      "outputs": [],
      "source": [
        "#To see the unique values in a column:\n",
        "print(df['Name'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcymwfDCs3Gk"
      },
      "outputs": [],
      "source": [
        "print(df['Email'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6elLp8HuuWyu"
      },
      "outputs": [],
      "source": [
        "print(df['Country'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WQ24afhwrLS"
      },
      "outputs": [],
      "source": [
        "#To check how many unique values each column has:\n",
        "print(df.nunique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZAbydRJyrLM"
      },
      "source": [
        "**Check for Duplicates**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWsWrwbGy5yw"
      },
      "outputs": [],
      "source": [
        "#To check if there are duplicate rows:\n",
        "print(df.duplicated().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6qmwAqKz5Bt"
      },
      "source": [
        "**Cleaning the Data: Address missing values, handle outliers, and ensure that the dataset is in a clean format for analysis.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_wRSdQbOw18"
      },
      "source": [
        "Cleaning this dataset is a crucial step before analysis.\n",
        " Here's how I can handle missing values, detect and remove outliers, and format my data properly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQoIfrijPNRg"
      },
      "source": [
        "**Handling Missing Values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffrx1D376hgI"
      },
      "outputs": [],
      "source": [
        "df['Job Title'].fillna('Unknown', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "546jj11zRKt5"
      },
      "outputs": [],
      "source": [
        "df_cleaned = df.copy()  # Creates a copy of df\n",
        "print(\"Missing values after removal:\\n\", df_cleaned.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu_E-dEiVy9Y"
      },
      "source": [
        "**Convert \"Date Of Birth\" to a proper datetime format.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9p0oJhu2JREq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert to datetime\n",
        "df[\"Date Of Birth\"] = pd.to_datetime(df[\"Date Of Birth\"], errors='coerce')\n",
        "\n",
        "# Check if conversion was successful\n",
        "print(df[\"Date Of Birth\"].dtype)  # Should now be datetime64[ns]\n",
        "print(df[\"Date Of Birth\"].head()) # Verify output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDzmp461Wygl"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(df.head())  # Check if dates are formatted correctly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrUT3OJhanum"
      },
      "source": [
        "**Formatted Telephone Numbers and removed non-numeric characters to ensure consistency.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FN8mU-tyatls"
      },
      "outputs": [],
      "source": [
        "#Cleaning the \"Telephone\" Column\n",
        "import re\n",
        "\n",
        "df[\"Telephone\"] = df[\"Telephone\"].astype(str).apply(lambda x: re.sub(r'\\D', '', x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGKOzudwbQdR"
      },
      "outputs": [],
      "source": [
        "print(df[\"Telephone\"].head())  # Displays the first 5 rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDET5PJQcz3I"
      },
      "outputs": [],
      "source": [
        "#Checking for duplicate records\n",
        "duplicates = df[df.duplicated()]\n",
        "print(duplicates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5s7Ut0D0k2p"
      },
      "source": [
        "**Feature Engineering: Create new features or modify existing ones if necessary.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H-OjDtl2_wL"
      },
      "source": [
        "## Create New Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poHFvbzN0pQy"
      },
      "source": [
        "**1) Age Calculation from Date of Birth**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SK8OJXn51KTY"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Convert \"Date Of Birth\" to datetime\n",
        "df[\"Date Of Birth\"] = pd.to_datetime(df[\"Date Of Birth\"], errors='coerce')\n",
        "\n",
        "# Calculate \"Age\"\n",
        "current_year = datetime.now().year\n",
        "df[\"Age\"] = current_year - df[\"Date Of Birth\"].dt.year"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch59b5tP1r5r"
      },
      "source": [
        "**2) Extract Features from Email**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsmp4FkG1ieh"
      },
      "outputs": [],
      "source": [
        "df[\"Email Username\"] = df[\"Email\"].apply(lambda x: x.split(\"@\")[0] if isinstance(x, str) else \"\")\n",
        "df[\"Email Domain\"] = df[\"Email\"].apply(lambda x: x.split(\"@\")[1] if isinstance(x, str) else \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnG48PXl1-J3"
      },
      "source": [
        "**3) Categorize Telephone Number Length**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5dqeWGc2MvF"
      },
      "outputs": [],
      "source": [
        "df[\"Telephone\"] = df[\"Telephone\"].astype(str).str.replace(r'\\D', '', regex=True)  # Remove non-numeric characters\n",
        "df[\"Telephone Length\"] = df[\"Telephone\"].apply(len)  # Count number of digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O731OXvK9o1O"
      },
      "outputs": [],
      "source": [
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUSuNwyQWN_a"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGtGT39HWRVh"
      },
      "source": [
        "**I will be using machine learning models, so numerical features like \"Age\" may need scaling:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZlg7AIzcSGj"
      },
      "outputs": [],
      "source": [
        "#First, convert \"Date Of Birth\" to a proper datetime format and calculate \"Age\"\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "\n",
        "# Convert \"Date Of Birth\" to datetime format\n",
        "df[\"Date Of Birth\"] = pd.to_datetime(df[\"Date Of Birth\"], format=\"%d/%m/%Y\", errors='coerce')\n",
        "\n",
        "# Calculate Age\n",
        "current_year = datetime.now().year\n",
        "df[\"Age\"] = current_year - df[\"Date Of Birth\"].dt.year\n",
        "\n",
        "# Verify Age column\n",
        "print(df[[\"Date Of Birth\", \"Age\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-Yzujg-jpnm"
      },
      "outputs": [],
      "source": [
        "#Once \"Age\" is created, I apply MinMax Scaling:\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "df[\"Age_Scaled\"] = scaler.fit_transform(df[[\"Age\"]])\n",
        "\n",
        "# Verify the scaling\n",
        "print(df[[\"Age\", \"Age_Scaled\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxDld-kN9zhV"
      },
      "outputs": [],
      "source": [
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6AdxsC8l6Ac"
      },
      "source": [
        "**Handling Text Encoding Issues (Fix non-ASCII characters in names, email, city, and country)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yalq81lP8W7w"
      },
      "source": [
        "My dataset contains text encoding issues, where characters appear as gibberish (ÃƒÂ©Ã‚â„¢Ã‚Â¶ÃƒÂ¥Ã‚Â¿Ã‚â€”ÃƒÂ¥Ã‚Â¼Ã‚Âº). This happens when a file is encoded in one format (e.g., UTF-8, Latin-1) but read in another. The code below are solutions to fix this issue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uubqDE_7_Ni"
      },
      "source": [
        "**Fix Already-Loaded Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFm5Ggzs9FNL"
      },
      "source": [
        "If some characters remain corrupted, I will remove non-ASCII characters using regex:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SgBNNKU9MgR"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# Function to remove non-ASCII characters\n",
        "def remove_non_ascii(text):\n",
        "    return re.sub(r'[^\\x00-\\x7F]+', '', text) if isinstance(text, str) else text\n",
        "\n",
        "# Apply to relevant columns\n",
        "for col in [\"Name\", \"Email\", \"City\", \"Country\"]:\n",
        "    df[col] = df[col].apply(remove_non_ascii)\n",
        "\n",
        "# Check the output\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2wEQqnNJuwJ"
      },
      "source": [
        "**Save and Download the Cleaned Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7rsvIGdFxIQ"
      },
      "outputs": [],
      "source": [
        "file_path = \"/content/drive/My Drive/Colab Notebooks/cleaned_data1.csv\"\n",
        "df.to_csv(file_path, index=False)\n",
        "print(f\"File saved to: {file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bE7JaBf-S64"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Save DataFrame as CSV\n",
        "df.to_csv(\"cleaned_data2.csv\", index=False)\n",
        "\n",
        "# Download the file\n",
        "files.download(\"cleaned_data2.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX2e4uNTzN0o"
      },
      "source": [
        "# **Exploratory Data Analysis (EDA) on customers.csv**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oNZxK2Ntrrx"
      },
      "source": [
        "**EDA helps understand data patterns, detect anomalies, and find relationships between variables. Below are key steps, along with how visualizations, correlation matrices, and summary statistics will help in analysis.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFe7RvNBz4z3"
      },
      "source": [
        "**1) Handle Missing Values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwuozpYd0AmF"
      },
      "outputs": [],
      "source": [
        "missing_values = df.isnull().sum()\n",
        "print(missing_values[missing_values > 0])  # Show columns with missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmnBGeON09Be"
      },
      "source": [
        "**Visualization: Bar Chart of Missing Values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4O_2qDG0Q8B"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.heatmap(df.isnull(), cbar=False, cmap=\"viridis\")\n",
        "plt.title(\"Missing Values Heatmap\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlcZrffF1Lnd"
      },
      "source": [
        "**3) Feature Engineering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7SXNLoH1OZA"
      },
      "outputs": [],
      "source": [
        "# Convert \"Date Of Birth\" into \"Age\"\n",
        "from datetime import datetime\n",
        "\n",
        "df[\"Date Of Birth\"] = pd.to_datetime(df[\"Date Of Birth\"], errors=\"coerce\")\n",
        "df[\"Age\"] = datetime.now().year - df[\"Date Of Birth\"].dt.year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HamQRU5f2qY0"
      },
      "outputs": [],
      "source": [
        "#Visualization: Age Distribution\n",
        "sns.histplot(df[\"Age\"], bins=20, kde=True)\n",
        "plt.title(\"Age Distribution of Customers\")\n",
        "plt.xlabel(\"Age\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWzqBFfJ-obe"
      },
      "outputs": [],
      "source": [
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuNFqQvm3HBX"
      },
      "source": [
        "**4) Categorical Data Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8E6k8qt3GiB"
      },
      "outputs": [],
      "source": [
        "#Top Cities & Countries\n",
        "print(df[\"City\"].value_counts().head(10))  # Top 10 cities\n",
        "print(df[\"Country\"].value_counts().head(10))  # Top 10 countries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dDPFRxp5xlz"
      },
      "outputs": [],
      "source": [
        "#Visualization: Top 10 Cities\n",
        "df[\"City\"].value_counts().head(10).plot(kind=\"bar\", figsize=(10, 5), color=\"skyblue\")\n",
        "plt.title(\"Top 10 Cities of Customers\")\n",
        "plt.xlabel(\"City\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VH5mVAp96E5I"
      },
      "source": [
        "**5) Correlation Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfmck0oL6MvD"
      },
      "outputs": [],
      "source": [
        "#Find numerical feature relationships:\n",
        "import numpy as np\n",
        "\n",
        "correlation_matrix = df.corr(numeric_only=True)\n",
        "print(correlation_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCsE3WaH6XZj"
      },
      "outputs": [],
      "source": [
        "# Visualization: Correlation Heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg8ZtyAf6oWu"
      },
      "source": [
        "**6) Gender Distribution**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gztbpnNj63XD"
      },
      "outputs": [],
      "source": [
        "df[\"Gender\"] = df[\"Gender\"].str.upper()  # Standardize to uppercase\n",
        "\n",
        "df[\"Gender\"].value_counts().plot(kind=\"bar\", color=[\"blue\", \"pink\"])\n",
        "plt.title(\"Gender Distribution of Customers\")\n",
        "plt.xlabel(\"Gender\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IpJHVA_7Btv"
      },
      "source": [
        "**7) Outlier Detection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-iu1u8U7HVb"
      },
      "outputs": [],
      "source": [
        "#Use Boxplot to find extreme values in \"Age\":\n",
        "sns.boxplot(x=df[\"Age\"])\n",
        "plt.title(\"Age Outliers\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNvU93xy-6Nh"
      },
      "outputs": [],
      "source": [
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKYZdZuXrn2q"
      },
      "source": [
        "**Identify any key insights, anomalies, or interesting trends that may guide the modeling process.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LX2vXqXJr2P5"
      },
      "source": [
        "** 1) Age Distribution Insights**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RD0gHpEvsp9a"
      },
      "outputs": [],
      "source": [
        "#Summary Statistics of Age\n",
        "print(df[\"Age\"].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0wytt0ps8xI"
      },
      "outputs": [],
      "source": [
        "# Group Age into Categories\n",
        "bins = [0, 18, 30, 45, 60, 100]  # Define age ranges\n",
        "labels = [\"<18\", \"18-30\", \"31-45\", \"46-60\", \"60+\"]\n",
        "df[\"Age Group\"] = pd.cut(df[\"Age\"], bins=bins, labels=labels)\n",
        "\n",
        "# Count by Age Group\n",
        "age_group_counts = df[\"Age Group\"].value_counts().sort_index()\n",
        "print(age_group_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sv6h2TkUts2K"
      },
      "source": [
        "**2) Gender Distribution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIaRju_htyu1"
      },
      "outputs": [],
      "source": [
        "#Count Unique Gender Values\n",
        "print(df[\"Gender\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBAakV7KuOzt"
      },
      "outputs": [],
      "source": [
        "#Pie Chart (For Percentage Representation)\n",
        "plt.figure(figsize=(6, 6))\n",
        "df[\"Gender\"].value_counts().plot.pie(autopct=\"%1.1f%%\", colors=[\"skyblue\", \"pink\"], startangle=90)\n",
        "plt.ylabel(\"\")  # Hide the y-label\n",
        "plt.title(\"Gender Distribution\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_56DGBqNujNn"
      },
      "outputs": [],
      "source": [
        "#Average Age by Gender\n",
        "print(df.groupby(\"Gender\")[\"Age\"].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-QfHodRuzr9"
      },
      "outputs": [],
      "source": [
        "# Gender Count by Country/City\n",
        "print(df.groupby([\"Country\", \"Gender\"])[\"Gender\"].count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oflUNUoQvzQ1"
      },
      "source": [
        "**3) Job Title Distribution Analysis in my Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhnZHfRuv4Tz"
      },
      "outputs": [],
      "source": [
        "#Check Unique Job Titles\n",
        "print(df[\"Job Title\"].nunique())  # Count of unique job titles\n",
        "print(df[\"Job Title\"].unique()[:10])  # Show first 10 unique job titles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6BCAhNxymI6"
      },
      "outputs": [],
      "source": [
        "#Count Job Titles & Handle \"Unknown\" Values\n",
        "print(df[\"Job Title\"].value_counts().head(10))  # Top 10 most common job titles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3gm5KGozWRa"
      },
      "source": [
        "**Visualize Job Title Distribution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MbSjGcSzLdB"
      },
      "outputs": [],
      "source": [
        "#Bar Chart (Top 10 Job Titles)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "top_jobs = df[\"Job Title\"].value_counts().head(10)\n",
        "sns.barplot(x=top_jobs.values, y=top_jobs.index, palette=\"coolwarm\")\n",
        "plt.xlabel(\"Count\")\n",
        "plt.ylabel(\"Job Title\")\n",
        "plt.title(\"Top 10 Most Common Job Titles\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HMcGDRZN0vg"
      },
      "source": [
        "**4) City & Country Distribution Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYhFC_6rN5yL"
      },
      "outputs": [],
      "source": [
        "# Count Unique Cities & Countries\n",
        "print(\"Unique Cities:\", df[\"City\"].nunique())\n",
        "print(\"Unique Countries:\", df[\"Country\"].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iga0ZOt-ODQC"
      },
      "outputs": [],
      "source": [
        "# Most Common Cities & Countries\n",
        "print(df[\"City\"].value_counts().head(10))  # Top 10 most common cities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGDawlEzbYx7"
      },
      "outputs": [],
      "source": [
        "# Group Data by Country & City\n",
        "print(df.groupby(\"Country\")[\"City\"].nunique())  # Unique cities per country\n",
        "print(df.groupby([\"Country\", \"City\"])[\"City\"].count())  # Customer count per city"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xdECqIF_ZGA"
      },
      "outputs": [],
      "source": [
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HY7zjuu2c5kQ"
      },
      "source": [
        "**5) Fixing Telephone Number Issues in my Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y198Q4Bfc96Y"
      },
      "outputs": [],
      "source": [
        "# Convert to String & Remove Scientific Notation\n",
        "df[\"Telephone\"] = df[\"Telephone\"].astype(str)  # Convert to string\n",
        "df[\"Telephone\"] = df[\"Telephone\"].apply(lambda x: x.split(\".\")[0] if \"e\" in x else x)  # Remove scientific notation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLQp3cYsdLnS"
      },
      "outputs": [],
      "source": [
        "# Standardize Phone Numbers\n",
        "import re\n",
        "\n",
        "df[\"Telephone\"] = df[\"Telephone\"].apply(lambda x: re.sub(r\"\\D\", \"\", x))  # Remove non-numeric characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucVqEn5adYHK"
      },
      "outputs": [],
      "source": [
        "# Filter Out Invalid Lengths\n",
        "df = df[df[\"Telephone\"].str.len().between(10, 15)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azLS0TO2dhB_"
      },
      "outputs": [],
      "source": [
        "# Remove Duplicates Telephone numbers\n",
        "df = df.drop_duplicates(subset=[\"Telephone\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDpAsboo_hmz"
      },
      "outputs": [],
      "source": [
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rk2PZWOrgOgH"
      },
      "source": [
        "## **Modeling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ySQGqJnfl0v"
      },
      "source": [
        "**I will train a Decision Tree Classifier to predict Job Titles**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hafH2-Cj197"
      },
      "source": [
        "**First I will Preprocess the Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1Sep0sEfwEH"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9e8UD51GpCls"
      },
      "outputs": [],
      "source": [
        "print(df[\"Job Title\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51K5zmV1sO1a"
      },
      "outputs": [],
      "source": [
        "# Remove \"Unknown\" Job Titles\n",
        "df_train = df[df[\"Job Title\"] != \"Unknown\"]\n",
        "df_test = df[df[\"Job Title\"] == \"Unknown\"]  # Save for later prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5otUB92szyo"
      },
      "outputs": [],
      "source": [
        "# Drop irrelevant columns (Name, Email, Telephone)\n",
        "df_train = df_train.drop(columns=[\"Customer ID\", \"Name\", \"Email\", \"Email Username\", \"Telephone\", \"Date Of Birth\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZjZyNX4v7fZ"
      },
      "outputs": [],
      "source": [
        "# Encode Categorical Features\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "categorical_cols = [\"City\", \"Country\", \"Gender\", \"Email Domain\", \"Age Group\"]\n",
        "label_encoders = {}\n",
        "\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df_train[col] = le.fit_transform(df_train[col].astype(str))  # Convert to string before encoding\n",
        "    label_encoders[col] = le  # Store encoder for later use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3S1GMK8TwMhx"
      },
      "outputs": [],
      "source": [
        "# Group Job Titles into Categories\n",
        "job_groups = {\n",
        "    \"Engineering\": [\"Designer, industrial/product\", \"Scientist, marine\"],\n",
        "    \"Healthcare\": [\"Dentist\", \"Pathologist\"],\n",
        "    \"Creative\": [\"Special effects artist\", \"Theme park manager\"],\n",
        "    \"Sports\": [\"Sports therapist\"],\n",
        "    \"Management\": [\"Accommodation manager\", \"Museum/gallery exhibitions officer\"],\n",
        "}\n",
        "\n",
        "# Assign job category\n",
        "df_train[\"Job Category\"] = df_train[\"Job Title\"].map(lambda x: next((k for k, v in job_groups.items() if x in v), \"Other\"))\n",
        "\n",
        "# Encode Job Category\n",
        "job_le = LabelEncoder()\n",
        "df_train[\"Job Category\"] = job_le.fit_transform(df_train[\"Job Category\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sfmgpfl2ieo"
      },
      "source": [
        "**Train Decision Tree Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRMf7wICwV4f"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Features and Target\n",
        "X = df_train.drop(columns=[\"Job Title\", \"Job Category\"])\n",
        "y = df_train[\"Job Category\"]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Train Decision Tree model\n",
        "dt_model = DecisionTreeClassifier(max_depth=8, random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# Validate model\n",
        "y_pred = dt_model.predict(X_val)\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "\n",
        "print(f\"Validation Accuracy: {accuracy:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KmTxqIu2rzL"
      },
      "source": [
        "**Predict Job Titles for \"Unknown\" Users**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict job category\n",
        "df_test[\"Predicted Job Category\"] = dt_model.predict(df_test)\n",
        "\n",
        "# Decode job categories back to names\n",
        "df_test[\"Predicted Job Title\"] = job_le.inverse_transform(df_test[\"Predicted Job Category\"])\n",
        "\n",
        "# Show first 10 predictions\n",
        "print(df_test[[\"Predicted Job Title\"]].head(10))"
      ],
      "metadata": {
        "id": "7eixkER9J5_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train and tune your models using cross-validation and hyperparameter optimization techniques.**"
      ],
      "metadata": {
        "id": "4NOuOOhMcvnR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will train and tune me Decision Tree model using Cross-validation and Hyperparameter optimization with GridSearchCV"
      ],
      "metadata": {
        "id": "HB4TFcztc4J9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) Train & Tune Decision Tree with Cross-Validation**"
      ],
      "metadata": {
        "id": "zZK66GGUdOle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "Lcb6B58MdE8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Filter out rows with 'Unknown' job titles for training\n",
        "df_train = df[df[\"Job Title\"] != \"Unknown\"].copy()\n",
        "df_test = df[df[\"Job Title\"] == \"Unknown\"].copy()"
      ],
      "metadata": {
        "id": "h3V8-oIEdYvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop Unnecessary Columns\n",
        "drop_cols = [\"Customer ID\", \"Name\", \"Email\", \"Email Username\", \"Telephone\", \"Date Of Birth\"]\n",
        "df_train.drop(columns=drop_cols, inplace=True)\n",
        "df_test.drop(columns=drop_cols + [\"Job Title\"], inplace=True)"
      ],
      "metadata": {
        "id": "h7BH0W6ke5Kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode Categorical Columns\n",
        "categorical_cols = [\"City\", \"Country\", \"Gender\", \"Email Domain\", \"Age Group\", \"Job Title\"]\n",
        "label_encoders = {}\n",
        "\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "\n",
        "    if col == \"Job Title\":\n",
        "        # Only fit on df_train since df_test has no 'Job Title'\n",
        "        le.fit(df_train[col].astype(str))\n",
        "        df_train[col] = le.transform(df_train[col].astype(str))\n",
        "    else:\n",
        "        full_data = pd.concat([df_train[col], df_test[col]], axis=0).astype(str)\n",
        "        le.fit(full_data)\n",
        "        df_train[col] = le.transform(df_train[col].astype(str))\n",
        "        df_test[col] = le.transform(df_test[col].astype(str))\n",
        "\n",
        "    label_encoders[col] = le\n"
      ],
      "metadata": {
        "id": "VjNHy1BPgw64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Features and Target\n",
        "X = df_train.drop(columns=[\"Job Title\"])\n",
        "y = df_train[\"Job Title\"]"
      ],
      "metadata": {
        "id": "f8_VMW4Eibyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tune Hyperparameters with Cross-Validation**"
      ],
      "metadata": {
        "id": "NOfxwykqmvH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up parameter grid for tuning\n",
        "param_grid = {\n",
        "    \"max_depth\": [10, 15, 20, 25],\n",
        "    \"min_samples_split\": [5, 10, 20],\n",
        "    \"min_samples_leaf\": [2, 5, 10],\n",
        "    \"criterion\": [\"gini\", \"entropy\"]\n",
        "}\n",
        "\n",
        "# Create model and GridSearchCV\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "grid_search = GridSearchCV(dt, param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "\n",
        "# Train model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best Parameters:\", grid_search.best_params_)"
      ],
      "metadata": {
        "id": "ao0ePR0ni5HB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Tuned Model\n",
        "best_dt = grid_search.best_estimator_\n",
        "y_pred = best_dt.predict(X_val)\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "\n",
        "print(f\"Validation Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "M4lpuXsMm3CZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View: Top Rows of the Training Data\n",
        "print(\"ðŸ”¹ Sample of Training Data:\")\n",
        "print(df_train.head())"
      ],
      "metadata": {
        "id": "rAX6a6JueTlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View: Features and Labels\n",
        "print(\"ðŸ”¹ Features (X_train):\")\n",
        "print(X_train.head())\n",
        "\n",
        "print(\"\\nðŸ”¹ Target Labels (y_train):\")\n",
        "print(y_train.head())"
      ],
      "metadata": {
        "id": "jyBnULWUn095"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View: Best Hyperparameters\n",
        "print(\"âœ… Best Parameters from Grid Search:\")\n",
        "print(grid_search.best_params_)"
      ],
      "metadata": {
        "id": "07Qppte-n7Np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on validation set\n",
        "y_pred = best_dt.predict(X_val)\n",
        "\n",
        "# Compare predictions with actual\n",
        "comparison_df = pd.DataFrame({\n",
        "    \"Actual\": y_val,\n",
        "    \"Predicted\": y_pred\n",
        "})\n",
        "print(\"ðŸ” Comparison of Actual vs Predicted Job Titles:\")\n",
        "print(comparison_df.head(10))"
      ],
      "metadata": {
        "id": "hiHuOWFGoTkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate the Decision Tree model performance using appropriate metrics (accuracy, precision, recall, F1 score, RMSE, etc.).**"
      ],
      "metadata": {
        "id": "xxyOHab6pdOA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating my model using multiple metrics gives a deeper understanding of its performance beyond just accuracy â€” especially in classification problems like predicting Job Titles.        Here's how to evaluate my Decision Tree model:"
      ],
      "metadata": {
        "id": "l6oDYVD6pkof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, mean_squared_error\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "9ZbQS60ppuw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate Model on Validation Set**"
      ],
      "metadata": {
        "id": "Uy6-wl8MqJCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on validation data\n",
        "y_pred = best_dt.predict(X_val)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f\"âœ… Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Precision, Recall, F1 Score\n",
        "precision = precision_score(y_val, y_pred, average='weighted')\n",
        "recall = recall_score(y_val, y_pred, average='weighted')\n",
        "f1 = f1_score(y_val, y_pred, average='weighted')\n",
        "\n",
        "print(f\"ðŸŽ¯ Precision: {precision:.2f}\")\n",
        "print(f\"ðŸ“¢ Recall: {recall:.2f}\")\n",
        "print(f\"ðŸ“Œ F1 Score: {f1:.2f}\")"
      ],
      "metadata": {
        "id": "BCStUeIep79E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "print(f\"ðŸ“‰ RMSE (just for info): {rmse:.2f}\")"
      ],
      "metadata": {
        "id": "Wh_OZCwRt_Zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analyze Feature Importance**"
      ],
      "metadata": {
        "id": "uq3gMcdssXJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Get feature importances\n",
        "importances = best_dt.feature_importances_\n",
        "features = X.columns\n",
        "\n",
        "# Create a DataFrame\n",
        "feat_df = pd.DataFrame({\"Feature\": features, \"Importance\": importances})\n",
        "feat_df = feat_df.sort_values(\"Importance\", ascending=False)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(data=feat_df, x=\"Importance\", y=\"Feature\", palette=\"viridis\")\n",
        "plt.title(\"ðŸ” Feature Importance from Decision Tree\")\n",
        "plt.xlabel(\"Importance Score\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "khwda3FpsJSe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}